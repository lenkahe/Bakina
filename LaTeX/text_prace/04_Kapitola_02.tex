\chapter{Matematická teória}

V tejto kapitole uvedieme znalosti z matematickej teórie, ktoré sú potrebné pre zostrojenie optimalizačných algoritmov, ktorými sa budeme zaoberať v následujúcich kapitolách. Najprv sa oboznámime s úvodom do regresnej analýzy a s neparametrickou metódou odhadu regresnej funkcie - metódou jadrových odhadov, ktorú použijeme na vyhladenie dát. Na konci kapitoly si ešte uvedieme vzorce pre aritmetický priemer, rozptyl a smerodajnú odchýlku, ktoré budú použité na redukciu dát. Pojmy a definície sú prebraté zo zdrojov...

%Po dôkladnom oboznámení sa s dátami, ktoré generuje performačný nástroj Perfcake sme usúdili, že ak dáta a teda grafy %``vyhladíme'', užívateľ nestratí podstatnú informáciu, ktorú dáta nesú. Po aplikovaní kĺzavých priemerov, sme sa %rozhodli použiť zovšeobecnenie tejto metódy a teda metódu jadrových odhadov. Prvá časť tejto kapitoly sa venuje úvodu %do tejto metódy. Budú použité definície a pojmy zo zdroja 1 a 2. 

%Po aplikovaní 
\section{Regresná analýza}
Pre pevné hodnoty nezávisle premennej $X$ (v našom prípade čas)  máme k dispozícií namerané hodnoty závisle premennej $Y$ (priepustnosť, použitá pamäť,...). Takýmito dvojicami bodov $(x_i, Y_i), i = 1,...,n$ chceme preložiť vhodnú krivku, tak aby boli odfiltrované výkyvy a bolo možné lepšie poznať štruktúru dát. Táto krivka sa nazýva \textit{regresná krivka} a jej príslušný regresný vzťah zapisujem v tvare

\begin{equation}
Y_i = m(x_i) + \varepsilon _i, i=1,...,n,
\end{equation}

kde \textit{m} je neznáma regresná funkcia a $\varepsilon _i, i = 1,...,n$, sú chyby merania. Cieľom regresnej analýzy je nájsť vhodnú aproximáciu $\hat{m}$ neznámej funkcie $m$. Hľadanie tejto regresnej krivky sa tiež nazýva \textit{vyhladzovanie} a je možné použiť dva spôsoby odhadu, \textit{parametricky} a \textit{neparametricky}:
\begin{itemize}
\item \textit{Parametrický prístup} - predpokladá, že regresná funkcia je nejakého predpísaného tvaru. Odhadnutá regresná funkcia bude teda určitého tvaru a bude ju popisovať množina parametrov - to je dôvod pre názov \textit{parametrický}.
\item \textit{Neparametrický prístup} - nepredpokladá predpísaný tvar regresnej funkcie. Tento prístup sa vyhýba parametrizácii a tvar funkcie sa odhaduje priamo z dát. Predpokladá sa jedine istá hladkosť hľadanej funkcie.
\end{itemize}

Jedna z najjednoduchších neparametrických metód je \textit{ metóda kĺzavých priemerov}. Pre odhad hodnoty $Y_i$ sa používa priemer niekoľkých hodnôt $Y_j,  j\in [i-h,i+h]$ v centrovanom okolí príslušného bodu $x_i$. \\*
Konkrétne,
 
\begin{equation}\label{metodaVazenychPriemerov}
\hat{m}(x) = \dfrac{\sum\limits_{i=1}^{n}  Y_i I_{[x - h, x + h]}(x_i)}{\sum\limits_{i=1}^{n} I_{[x - h, x + h]}(x_i)}.
\end{equation}
Na vyjadrenie 
\begin{equation}\label{indikatorovaFunkcia}
I_{[j,k]}(x) \begin{cases}
1 & x \in [j,k], \\ 
0 & $inak.$
\end{cases}
\end{equation}
sa používa \textit{indikátorová funkcia} $I_{[j,k]}(x)$.

Jadrové odhady sa považujú za zovšeobecnenie \textit{metódy kĺzavých priemerov}.


\section{Jadrové odhady}\label{JadroveOdhady}

Pri odhadovaní regresnej funkcie pomocou jadrových odhadov, sa používajú vážené hodnoty $Y$ v centrovanom okolí príslušného bodu $x_i$. Váhy hodnôt $Y$ sú závislé na vzdialenosti príslušných $x$ bodov od konkrétneho $x_i$, bližšie hodnoty  -  väčšia váha. Toto nám pomáha dosiahnuť \textit{jadrová funkcia}. 
Vzorec pre jadrové odhady vo všeobecnosti, môžme zapísať nasledovne
\begin{equation}
\hat{m}(x,h) = \sum\limits_{i=1}^{n} W_i(x,h)Y_i,
\end{equation}
kde $ W_i(x,h)$ je váhová funkcia s vyhladzovacím parametrom \textit{h}. Ide teda o akýsi vážený súčet pozorovaní, ktorý v jednom z najjednoduchších prípadov môže mať tvar
\begin{equation}\label{vahovaFunkcia}
W_i(x,h) = K_h(x - x_i) = \frac{1}{h}K\Big(\frac{x-x_i}{h}\Big),
\end{equation}
kde \textit{K} je jadrová funkcia. Váhová funkcia by mala dávať súčet váh 1.

\subsection{Jadrová funkcia}
\begin{figure}[!ht]
\centering
\begin{subfigure}{.3\textwidth}
  \centering
  \includegraphics[scale=0.15]{Epanecnikovo.pdf}
  \caption{Epanečnikovo jadro}
\end{subfigure}%
\begin{subfigure}{.3\textwidth}
  \centering
  \includegraphics[scale=0.15]{quadratic.pdf}
  \caption{Kvadratické jadro}
\end{subfigure}
\begin{subfigure}{.3\textwidth}
  \centering
  \includegraphics[scale=0.15]{Gaussian.pdf}
  \caption{Gaussovo jadro}
\end{subfigure}
\begin{subfigure}{.3\textwidth}
  \centering
  \includegraphics[scale=0.15]{uniform.pdf}
  \caption{Obdĺžnikové jadro}
\end{subfigure}
\begin{subfigure}{.3\textwidth}
  \centering
  \includegraphics[scale=0.15]{triangular.pdf}
  \caption{Trojuholníkové jadro}
\end{subfigure}
\begin{subfigure}{.3\textwidth}
  \centering
  \includegraphics[scale=0.15]{smiesne.pdf}
  \caption{Nepomenované jadro}
\end{subfigure}
\centering
\caption{Rôzne tvary jadrových funkcií:}\label{kernelShapeTypes}
\begin{tabular}{ l l l }
 a) $K(x)=\frac{3}{4}(1-x^2)I_{[-1,1]}(x)$, & b) $K(x)=\frac{15}{16}(1-x^2)^2I_{[-1,1]}(x)$, & c) $K(x)=\frac{1}{\sqrt{2\pi}}e^-\frac{x^2}{2} $, \\
 d) $K(x)=\frac{1}{2}I_{[-1,1]}(x) $, & e) $K(x)=(1-|x|)I_{[-1,1]}(x)$, & f) $K(x)=\frac{1}{2}e^{-|x|}$
 \end{tabular}
 
\end{figure}

Jadrová funkcia determinuje tvar vyhladzovacej funkcie. Na obrázku \ref{kernelShapeTypes} môžme vidieť niekoľko najpoužívanejších jadrových funkcií. V popise funkcie sa používa indikátorová funkcia (\ref{indikatorovaFunkcia}).

Vo všeobecnosti hocijaká integrovatelná, obmedzená funkcia, ktorá spĺňa kritériá \ref{criterion} môže byť jadrom.
\begin{align}\label{criterion}
\begin{split}
a) \int K(z)dz = 1 \qquad & b) \int zK(z)dz = 0 \\ 
c) \int z^2K(z)dz < \infty \qquad & d) K(x) \geq 0 \enspace \textrm{pre všetky} \enspace x.
\end{split}
\end{align} 

\subsection{Šírka vyhladzovacieho okna}

Okrem jadrovej funkcie, alebo jadra, je ďalším dôležitým parametrom tejto metódy šírka vyhladzovacieho okna $h$. Šírka vyhladzovacieho okna alebo aj vyhladzovací parameter \textit{h} udáva šírku vyhladzovacej funkcie a teda aj silu vyhladenia. 

Malá šírka vyhladzovacieho okna znamená, že odhad závisí na úzkom okolí bodu $x_i$ a teda odhad do veľkej miery reprodukuje pôvodné dáta. Naopak, ak zvolíme vysokú hodnotu $h$, aj veľmi vzdialené hodnoty majú vysoký dopad na odhad, čo vedie k ``prehladeniu'' a pri dostatočne veľkej šírke $h$ až k priemeru dát.

 Spomínané rozdieli v šírke vyhladzovacieho okna môžme vidieť na obrázku \ref{porovnanieSirky}. Pre ilustráciu vplyvu vyhladzovacieho parametra sú použité reálne dáta z merania použitej pamäte nástroja PerfCake. Aplikované sú Nadaraya-Watsonove odhady, ktoré sú popísané v nasledujúcej podkapitole, s Epanečnikovým jadrovou funkciou. 
 
 \begin{figure}[!ht]
  \includegraphics[scale=0.45]{jadro1.png}
  \hspace{15px}
  \includegraphics[scale=0.45]{jadro10.png}
   
   \vspace{30px}
   
  \centering
  \includegraphics[scale=0.45]{jadro5.png}
  \caption{Porovnanie šírky vyhladzovacieho okna, bodky sú pôvodné dáta, súvislá čiara odhadnutá regresná funkcia}\label{porovnanieSirky}
\end{figure}

\subsection{Vhodný výber vyhladzovacieho parametra}
Hoci je v praxi bežné vybrať vhodnú šírku vyhladzovacieho okna na základe niekoľkých pokusov a následného subjektívneho výberu, existuje niekoľko metód pre výber optimálnej šírky vyhladzovacieho okna.

Kvalita jadrových odhadov regresnej funkcie môže byť lokálne popísaná pomocou \textit{strednej kvadratickej chyby (MSE - Mean Square Error)}
\begin{equation*}
MSE\{\hat{m}(x,h)\} = E{\{\hat{m}(x,h) - m(x)\}}^2.
\end{equation*} 
\\
Alebo tiež pomocou globálnej chyby - \textit{priemernej strednej kvadratickej chyby (AMSE - average MSE)}
\begin{equation*}
AMSE\{\hat{m}(.,h)\} = \frac{1}{n}E\sum\limits_{i=1}^{n} {\{\hat{m}(x_i,h) - m(x_i)\}}^2.
\end{equation*}
Minimalizovaním týchto chýb pre hodnotu parametra $h$, dostávame jeho optimum.

Keďže vzorec pre AMSE obsahuje neznáme hodnoty regresnej funkcie, použijeme pre výpočet optimálnej hodnoty parametra $h$, \textit{reziduálny súčet štvorcov (RSS)}, kde tieto neznáme hodnoty nahradíme nameranými hodnotami $Y_i$.
Teda
\begin{equation}
 RSS_n(h) = \frac{1}{n}\sum\limits_{i=1}^{n} {\{Y_i - \hat{m}(x_i,h)\}}^2.
\end{equation}
 RSS ale nie je nestranným odhadom AMSE, preto sa metódy pre odhad optimálnej šírky vyhladzovacieho okna snažia RSS upraviť tak, aby bol nestranný. 
 
 Jedna z najpoužívanejších metód tohto typu je \textit{metóda krížového overenia (Cross-validation method)}. Táto metóda spočíva vo vynechaní pozorovania $x_j$ pre spočítanie odhadu v bode $x_j$
 \begin{equation*}
\hat{m}_{-j}(x_j,h) = \sum\limits_{\substack{i=1 \\ i\neq j}}^{n}W_i(x_j,h)Y_i.
\end{equation*}
S použitím tejto modifikácie, môžme RSS prepísať do tvaru
\begin{equation}\label{CV}
CV(h) = \frac{1}{n}\sum\limits_{i=1}^{n} {\{Y_i - m_{-i}(x_i)\}}^2,
\end{equation}
funkcia CV je tiež známa ako ``cross-validačná'' funkcia. Odhadnuté optimálne $h$ dostaneme minimalizovaním (\ref{CV})
\begin{equation}
\hat{h}_{CV} = \underset{h \in H_n}{\textrm{ arg min }} CV(h).
\end{equation}
Aj keď je táto metóda jedna z najpoužívanejších, negarantuje nestrannosť odhadu, ani že $\hat{h}_{CV}$ minimalizuje AMSE (alebo hocijakú inú chybovú mieru). Dôsledkom toho je, že $\hat{h}_{CV}$  nadobúda väčšinou jemne nižšiu hodnotu ako je optimálna šírka $h$.

Viac o metóde krížového overenia, ale aj iných metódach na odhad optimálnej šírky vyhladzovacieho okna, napr. Malloowsova metóda, Penalizačná metóda, alebo metóda založená na Fourierovej transformácii, môžme nájsť v [(Kernel smoothing)].
\subsection{Typy jadrových odhadov}
V tejto podkapitole si uvedieme niektoré najznámejšie typy jadrových odhadov, ktoré sú uvedené v zdrojoch ...

Ak ako váhovú funkciu použijeme (\ref{vahovaFunkcia}) dostávame \textbf{Priestley-Chaove odhady}
\begin{equation}
\hat{m}_{PCH}(x,h) = \frac{1}{n} \sum\limits_{i=1}^{n} K_h(x - x_i)Y_i.
\end{equation}
Modifikovaním tohto estimátora získame ďalší známy typ jadrových odhadov, \textbf{Gasser-Müllerove odhady}
\begin{equation}
\hat{m}_{GM}(x,h) = \sum\limits_{i=1}^{n} Y_i \int\limits_{s_i-1}^{s_i}K_h(t-x)dt,
\end{equation}
kde $s_0 = 0 , s_i = \frac{x_i + x_{i+1}}{2}, s_n = 1$, pre $x_i$ ekvidištantne rozdelené na [0,1]. Tento estimátor sa dá vhodne použiť pre odhad derivácie regresnej funkcie.

Nasledujúce typy jadrových odhadov vychádzajú z takzvaných \textit{lokálne polynomiálnych jadrových odhadov}. Odhad neznámej regresnej funkcie v bode $x$ je získaný preložením polynómu stupňa $d$ váženou metódou najmenších štvorcov. Nech tento polynóm má tvar
\begin{equation}
P(u)=\beta_0 + \beta_1(u - x) + ... + \beta_d(u - x)^d.
\end{equation}
Váhy sú dané pomocou jadrovej funkcie 
\begin{equation} \label{jadrovaFunkcia}
K_h(x - x_i) = \frac{1}{h}K\Big(\frac{x-x_i}{h}\Big).
\end{equation}
Aplikujeme váženú metódu najmenších štvorcov, to znamená, že minimalizujeme výraz 
\begin{equation}\label{minimVyraz}
 \sum\limits_{i=1}^{n} \{Y_i - \beta_0 - \beta_1(x_i - x) - ... - \beta_d(x_i - x)^p\}^2 K_h(x_i - x)
\end{equation}
v závislosti na parametroch $\pmb{\beta} = (\beta_0,...,\beta_d)'$. Označme $\pmb{\hat{\beta}} = (\hat{\beta}_0,...,\hat{\beta}_d)'$ vektor, pre ktorý (\ref{minimVyraz}) nadobúda minimum. Odhad regresnej funkcie získaný popísanou metódou  je  hodnota parametra $\hat{\beta}_0$.\\
Špeciálnym prípadom lokálne polynomiálnych odhadov, kde stupeň polynómu $d = 0$ sú \textbf{Nadaraya-Watsonove odhady}
\begin{equation}\label{Nadaraya-Watson}
\hat{m}_{NW}(x,h) = \frac{\sum\limits_{i=1}^{n} K_h(x - x_i)Y_i}{\sum\limits_{i=1}^{n} K_h(x - x_i)}.
\end{equation}
V tomto prípade prekladáme dáta konštantnou funkciou. Môžme si tiež všimnúť, že ak použijeme Nadaraya-Watsonove odhady s obdĺžnikovou jadrovou funkciou, dostaneme metódu kĺzavých priemerov (\ref{metodaVazenychPriemerov}).\\
Druhým špeciálnym prípadom lokálne polynomiálnych odhadov, kde stupeň polynómu $d = 1$ a ide teda o priamku, sú 
 \textbf{Lokálne lineárne estimátory}
\begin{equation}
\hat{m}_{LL}(x,h) = \frac{1}{n}\sum\limits_{i=1}^{n}\frac{{\hat{s}_2(x;h) - \hat{s}_1(x;h)(x_i - x)}K_h(x-x_i)Y_i}{\hat{s}_2(x;h)\hat{s}_0(x;h) - \hat{s}_1(x;h)^2},
\end{equation}
kde 
\begin{equation}
\hat{s}_r(x,h) = \frac{1}{n}\sum\limits_{i=1}^{n}(x_i - x)^rK_h(x-x_i).
\end{equation}



\section{Miera polohy a miera variability}
Ako bolo uvedené na začiatku kapitoly, v tejto podkapitole sa oboznámime ešte s niektorými pojmami zo štatistiky.

Majme \textit{súbor hodnôt} nejakej náhodnej veličiny
 \begin{equation}
x_1,x_2,x_3,...,x_n,
\end{equation}  
kde \textit{n} je rozsah súboru a jeho hodnoty sú intervalového alebo pomerového typu. To znamená, že je možné  stanoviť vzdialenosti medzi meranými hodnotami, a teda počítať s ich rozdielami. Tento súbor hodnôt môžme analyzovať niekoľkými spôsobmi. Oboznámime sa niekoľkými charakteristikami takýchto náhodných veličín.

\subsection{Aritmetický priemer}
Na určenie hodnoty, okolo ktorej sa hodnoty jednotlivých pozorovaní nachádzajú je vhodný aritmetický priemer daného súboru. 

\begin{equation}
\bar{x} = \frac{1}{n} \sum\limits_{i=1}^{n} x_i
\end{equation}

Aritmetický priemer je tiež nazývaný miera polohy štatistických znakov.

\subsection{Rozptyl a smerodajná odchýlka}

Miery variability určujú, spôsob akým sú merané hodnoty usporiadané okolo strednej hodnoty. Najpoužívanejšie miery variability sú rozptyl a smerodajná odchýlka.

Rozptyl je  často označovaný ako \textit{stredná kvadratická odchýlka} a je definovaný
\begin{equation}
s^2 = \frac{1}{n}\sum\limits_{i=1}^{n}(x_i - \bar{x})^2.
\end{equation}

V prípade, že rozptyl počítame iba zo vzorky hodnôt, a nie z celého súboru hodnôt, vzorec sa zmení na
 \begin{equation}
s^2 = \frac{1}{n-1}\sum\limits_{i=1}^{n}(x_i - \bar{x})^2,
\end{equation}
vďaka tejto úprave bude vypočítaný rozptyl jemne väčší, čím sa stáva nestranným odhadom skutočného rozptylu. Táto korektúra sa používa na zmiernenie zkreslenia výsledku pri výpočte zo zmenšeného počtu dát.

Smerodajná odchýlka je daná ako odmocnina z rozptylu
\begin{equation}
s = \sqrt{s^2}.
\end{equation}

Čím väčšie hodnoty rozptyl a smerodajná odchýlka naberajú, tým viac sú hodnoty rozptýlené od priemeru, naopak menšie hodnoty indikujú ``tesnejšie'' usporiadanie meraných hodnôt.


